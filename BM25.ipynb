{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgzWBIcWUiC4NGuo+sU+xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliano-soares/2017-primeiro-semestre/blob/master/BM25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3bc2ocewQpr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zOA9pTIQnhd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "class BM25:\n",
        "    def __init__(self, documents: List[str]):\n",
        "        self.documents = documents\n",
        "        self.total_docs = len(documents)\n",
        "        self.avg_doc_len = sum([len(doc) for doc in documents]) / self.total_docs\n",
        "        self.k1 = 1.2\n",
        "        self.b = 0.75\n",
        "        self.idf = self.compute_idf()\n",
        "        self.document_scores = []\n",
        "\n",
        "    def compute_idf(self) -> dict:\n",
        "        word_doc_freq = {}\n",
        "        for document in self.documents:\n",
        "            words = set(document.split())\n",
        "            for word in words:\n",
        "                word_doc_freq[word] = word_doc_freq.get(word, 0) + 1\n",
        "        return {word: math.log((self.total_docs - freq + 0.5) / (freq + 0.5)) for word, freq in word_doc_freq.items()}\n",
        "\n",
        "    def score(self, query: str, document_index: int) -> float:\n",
        "        query_words = Counter(query.split())\n",
        "        score = 0\n",
        "        for word, count in query_words.items():\n",
        "            if word not in self.idf:\n",
        "                continue\n",
        "            term_frequency = self.documents[document_index].count(word)\n",
        "            numerator = self.idf[word] * term_frequency * (self.k1 + 1)\n",
        "            denominator = term_frequency + self.k1 * (1 - self.b + self.b * (len(self.documents[document_index]) / self.avg_doc_len))\n",
        "            score += numerator / denominator\n",
        "        return score\n",
        "\n",
        "    def rank(self, query: str, n_results: int = 10) -> List[Tuple[int, float]]:\n",
        "        self.document_scores = []\n",
        "        for i in range(self.total_docs):\n",
        "            self.document_scores.append((i, self.score(query, i)))\n",
        "        self.document_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return self.document_scores[:n_results]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_document(doc: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes punctuations and lowercases the given document\n",
        "    \"\"\"\n",
        "    return doc.translate(str.maketrans('', '', string.punctuation)).lower()"
      ],
      "metadata": {
        "id": "QPaYhyM7Q2Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(file_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Loads the documents from the given file path and preprocesses them\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        documents = f.readlines()\n",
        "        documents = [preprocess_document(doc) for doc in documents]\n",
        "    return documents"
      ],
      "metadata": {
        "id": "8RyJbVoxQ3Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class main to load the files and instantiate as a class.\n",
        "The queries variable is a list of strings with the search you want to do.\n",
        "\n",
        "The returned result and the ID of the top 5 documents based on the entered query."
      ],
      "metadata": {
        "id": "7T5glc66Q_1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Loading documents from file\n",
        "    file_path = 'cisi/CISI.ALL'\n",
        "    documents = load_documents(file_path)\n",
        "\n",
        "    # Initializing the BM25 model\n",
        "    bm25 = BM25(documents)\n",
        "\n",
        "    # Evaluating the model with sample queries\n",
        "    queries = ['circuit design', 'information retrieval']\n",
        "    for query in queries:\n",
        "        results = bm25.rank(query, n_results=5)\n",
        "        print(f\"Top 5 results for query '{query}':\")\n",
        "        for result in results:\n",
        "            print(f\"\\tDocument {result[0]} with score {result[1]}\")"
      ],
      "metadata": {
        "id": "UmV8TwEoQ-A-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}